{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6400/6429 [============================>.] - ETA: 0s - loss: 0.9504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ying/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6528/6429 [==============================] - 113s - loss: 0.9343 - val_loss: 0.2552\n",
      "Epoch 2/5\n",
      "6528/6429 [==============================] - 111s - loss: 0.1180 - val_loss: 0.2421\n",
      "Epoch 3/5\n",
      "6528/6429 [==============================] - 96s - loss: 0.1059 - val_loss: 0.2283\n",
      "Epoch 4/5\n",
      "6528/6429 [==============================] - 96s - loss: 0.0981 - val_loss: 0.2154\n",
      "Epoch 5/5\n",
      "6528/6429 [==============================] - 99s - loss: 0.0942 - val_loss: 0.2096\n",
      "Saving model weights and configuration file.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Lambda, ELU\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "\n",
    "def read_data():\n",
    "    data_path = \"driving_log.csv\"\n",
    "    columns = ['center_image','left_image','right_image','angle','throttle','speed']\n",
    "    df = pd.read_csv(data_path, header = None, names = columns)\n",
    "    \n",
    "    center_images = df.center_image.tolist()\n",
    "    angle = df.angle.tolist()\n",
    "    left_images = df.left_image.tolist()\n",
    "    right_images = df.right_image.tolist()\n",
    "    \n",
    "    return (center_images, angle, left_images, right_images)\n",
    "    \n",
    "    \n",
    "        \n",
    "def shuffle(center_images, angle):\n",
    "    \n",
    "    return shuffle(center_images, angle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_model(time_len=1):\n",
    "    #ch, row, col = 3, 160, 320  # camera format\n",
    "    ch, row, col = 160, 320, 3\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(ch, row, col),\n",
    "            output_shape=(ch, row, col)))\n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\",W_regularizer = l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\",W_regularizer = l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\",W_regularizer = l2(0.001)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def flip(image, angle):\n",
    "  new_image = cv2.flip(image,1)\n",
    "  new_angle = angle*(-1)\n",
    "  return new_image, new_angle\n",
    "\n",
    "\n",
    "def train_generator(batch_size, center_list, angle_list):\n",
    "    \n",
    "    while 1:\n",
    "        train_center = np.zeros((batch_size,160, 320, 3), dtype = np.float32)\n",
    "        train_angle = np.zeros((batch_size,), dtype = np.float32)\n",
    "        \n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            rand = int(np.random.choice(len(center_list),1))\n",
    "         \n",
    "            train_center[i] = mpimg.imread(center_list[i].lstrip())\n",
    "            train_angle[i] = angle_list[i]\n",
    "            \n",
    "            flip_coin = random.randint(0,1)\n",
    "            \n",
    "            if flip_coin == 1:\n",
    "                train_center[i], train_angle[i] = flip(train_center[i], train_angle[i])\n",
    "        \n",
    "        yield train_center, train_angle\n",
    "            \n",
    "\n",
    "\n",
    "center, angle, left, right = read_data()\n",
    "\n",
    "\n",
    "center_train, center_valid, angle_train, angle_valid = train_test_split(center, angle, test_size = 0.20, random_state = 100) \n",
    "\n",
    "\n",
    "d_straight, d_left, d_right = [], [], []\n",
    "a_straight, a_left, a_right = [], [], []\n",
    "\n",
    "#for i in (0,len(center)-1):\n",
    "#    d_right.append(right[i])\n",
    "#    a_right.append(angle[i]-0.25)\n",
    "#    d_left.append(left[i])\n",
    "#a_left.append(angle[i]+0.25)\n",
    "\n",
    "final_train_image = center_train+d_right+d_left\n",
    "final_train_angle = angle_train+a_right+a_left\n",
    "\n",
    "batch_size = 128\n",
    "train_gen = train_generator(batch_size, final_train_image, final_train_angle)\n",
    "valid_gen = train_generator(batch_size, center_valid, angle_valid)\n",
    "\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.fit_generator(\n",
    "train_gen,\n",
    "samples_per_epoch=math.ceil(len(center_train)),\n",
    "nb_epoch=5,\n",
    "validation_data=valid_gen,\n",
    "nb_val_samples=len(center_valid)\n",
    ")\n",
    "print(\"Saving model weights and configuration file.\")\n",
    "\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "with open('model.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)\n",
    "\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND-TensorFlow-Lab]",
   "language": "python",
   "name": "conda-env-CarND-TensorFlow-Lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
